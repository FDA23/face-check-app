import streamlit as st
import mediapipe as mp
import cv2
import numpy as np
from PIL import Image, ImageOps

# --- è¨­å®šã¨é–¢æ•°å®šç¾© ---
st.set_page_config(page_title="é¡”ãƒãƒ©ãƒ³ã‚¹ï¼†è‚Œæ¯”è¼ƒè¨ºæ–­", layout="wide")

# MediaPipeã®åˆæœŸåŒ–
mp_face_mesh = mp.solutions.face_mesh
mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
st.sidebar.title("è¨­å®š")
edge_threshold = st.sidebar.slider("ã—ã‚æ¤œå‡ºæ„Ÿåº¦", 50, 250, 150, help("æ•°å€¤ã‚’ä¸‹ã’ã‚‹ã¨ç´°ã‹ã„ç·šã‚’æ‹¾ã„ã€ä¸Šã’ã‚‹ã¨æ·±ã„ç·šã ã‘æ‹¾ã„ã¾ã™ã€‚"))
st.sidebar.info("â€»æ„Ÿåº¦ã¯ä¸¡æ–¹ã®ç”»åƒã«åŒã˜ã‚ˆã†ã«é©ç”¨ã•ã‚Œã¾ã™ã€‚")

def load_and_fix_image(uploaded_file):
    """ç”»åƒã‚’èª­ã¿è¾¼ã¿ã€å›è»¢ã‚’ç›´ã—ã€ãƒªã‚µã‚¤ã‚ºã™ã‚‹é–¢æ•°"""
    image = Image.open(uploaded_file)
    image = ImageOps.exif_transpose(image)
    image = image.convert('RGB')
    
    max_width = 600
    if image.width > max_width:
        ratio = max_width / image.width
        new_height = int(image.height * ratio)
        image = image.resize((max_width, new_height))
    
    return np.array(image)

def draw_mesh(image, landmarks_proto):
    """é¡”ã®ãƒ¡ãƒƒã‚·ãƒ¥ï¼ˆéª¨æ ¼ï¼‰ã‚’æç”»ã™ã‚‹é–¢æ•°"""
    annotated_image = image.copy()
    mp_drawing.draw_landmarks(
        image=annotated_image,
        landmark_list=landmarks_proto,
        connections=mp_face_mesh.FACEMESH_TESSELATION,
        landmark_drawing_spec=None,
        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())
    mp_drawing.draw_landmarks(
        image=annotated_image,
        landmark_list=landmarks_proto,
        connections=mp_face_mesh.FACEMESH_CONTOURS,
        landmark_drawing_spec=None,
        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style())
    return annotated_image

def analyze_area(image, landmarks_list, indices, area_name):
    """æŒ‡å®šã‚¨ãƒªã‚¢ã‚’åˆ‡ã‚ŠæŠœãã€ã‚¨ãƒƒã‚¸ï¼ˆã—ã‚ï¼‰ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°"""
    image_height, image_width, _ = image.shape
    pts = []
    for idx in indices:
        pt = landmarks_list[idx]
        pts.append([int(pt.x * image_width), int(pt.y * image_height)])
    
    if not pts: return 0, None

    pts = np.array(pts)
    x, y, w, h = cv2.boundingRect(pts)
    
    margin = 10
    x, y = max(0, x-margin), max(0, y-margin)
    w, h = min(w+margin*2, image_width-x), min(h+margin*2, image_height-y)
    
    roi = image[y:y+h, x:x+w]
    if roi.size == 0: return 0, None

    gray = cv2.cvtColor(roi, cv2.COLOR_RGB2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    edges = cv2.Canny(blurred, edge_threshold, edge_threshold * 1.5)
    score = np.sum(edges > 0) / edges.size * 1000
    
    return score, (x, y, w, h)

def process_image(img_array, face_mesh):
    """1æšã®ç”»åƒã‚’å‡¦ç†ã—ã¦çµæœã‚’è¿”ã™é–¢æ•°"""
    results = face_mesh.process(img_array)
    if not results.multi_face_landmarks:
        return None

    face_landmarks_proto = results.multi_face_landmarks[0] 
    face_landmarks_list = face_landmarks_proto.landmark

    mesh_img = draw_mesh(img_array, face_landmarks_proto)
    analyzed_img = img_array.copy()
    scores = {}

    # --- è§£æã‚¨ãƒªã‚¢ã®å®šç¾©ï¼ˆç¯„å›²æ‹¡å¤§ç‰ˆï¼‰---
    
    # ãŠã§ã“ï¼ˆå¤‰æ›´ãªã—ï¼‰
    forehead_idx = [109, 338, 9, 336, 151]
    
    # ã»ã†ã‚Œã„ç·šã‚¨ãƒªã‚¢ï¼ˆé ¬éª¨ã®ä¸‹ã‹ã‚‰å°é¼»ã®æ¨ªã‚’å«ã¿ã€å£è§’ã¾ã§ï¼‰
    nasolabial_idx = [
        205, 203, 36, 101, 50, 123, 117, 111, 147, 187, 207, # å·¦é ¬å‘¨è¾º
        425, 423, 266, 330, 280, 352, 346, 340, 376, 411, 427 # å³é ¬å‘¨è¾º
    ]
    
    # å£å‘¨ã‚Šãƒ»ãƒãƒªã‚ªãƒãƒƒãƒˆãƒ©ã‚¤ãƒ³ï¼ˆå£è§’ã®ä¸‹ã€ã‚ã”å‘¨è¾ºã¾ã§åºƒãï¼‰
    marionette_idx = [
        57, 186, 212, 287, 410, 432, 273, 335, 406, 313, 18, 83, 182, 106, 43 # å£å‘¨ã‚Šã¨ã‚ã”
    ]

    areas = {
        "ãŠã§ã“": (forehead_idx, (0, 255, 0)),        # ç·‘
        "ã»ã†ã‚Œã„ç·šå‘¨è¾º": (nasolabial_idx, (255, 165, 0)), # ã‚ªãƒ¬ãƒ³ã‚¸
        "å£å…ƒãƒ»ã‚ã”å‘¨ã‚Š": (marionette_idx, (255, 0, 255))  # ãƒ”ãƒ³ã‚¯
    }

    for name, (indices, color) in areas.items():
        score, rect = analyze_area(img_array, face_landmarks_list, indices, name)
        scores[name] = score
        if rect:
            x, y, w, h = rect
            cv2.rectangle(analyzed_img, (x, y), (x+w, y+h), color, 2)

    return mesh_img, analyzed_img, scores

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢æ§‹æˆ ---
st.title("ğŸ“¸ é¡”ãƒãƒ©ãƒ³ã‚¹ï¼†è‚Œæ¯”è¼ƒè¨ºæ–­ (åºƒç¯„å›²ç‰ˆ)")
st.write("2æšã®å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€éª¨æ ¼ã®ã‚†ãŒã¿ã¨è‚Œã®çŠ¶æ…‹ï¼ˆã—ã‚ãƒ»ã‚­ãƒ¡ï¼‰ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚")

col1, col2 = st.columns(2)
with col1:
    file_a = st.file_uploader("ç”»åƒA (Before)", type=["jpg", "png"], key="a")
with col2:
    file_b = st.file_uploader("ç”»åƒB (After)", type=["jpg", "png"], key="b")

if file_a and file_b:
    with st.spinner("2æšã®ç”»åƒã‚’è§£æä¸­..."):
        img_a = load_and_fix_image(file_a)
        img_b = load_and_fix_image(file_b)

        with mp_face_mesh.FaceMesh(
            static_image_mode=True,
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.5) as face_mesh:

            result_a = process_image(img_a, face_mesh)
            result_b = process_image(img_b, face_mesh)

        if result_a and result_b:
            mesh_a, analyzed_a, scores_a = result_a
            mesh_b, analyzed_b, scores_b = result_b

            st.divider()
            st.header("1. éª¨æ ¼ãƒ»ã‚†ãŒã¿ã®å¯è¦–åŒ–")
            st.info("ğŸ’¡ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ: æ­£ä¸­ã®ãƒ©ã‚¤ãƒ³ã¯çœŸã£ç›´ãã‹ï¼Ÿ å·¦å³ã®ç›®ã®é«˜ã•ã¯åŒã˜ã‹ï¼Ÿ ç¶²ç›®ã®å½¢ã«æ³¨ç›®ã—ã¦ãã ã•ã„ã€‚")
            col1_mesh, col2_mesh = st.columns(2)
            col1_mesh.image(mesh_a, caption="ç”»åƒA: éª¨æ ¼ãƒ¡ãƒƒã‚·ãƒ¥", use_container_width=True)
            col2_mesh.image(mesh_b, caption="ç”»åƒB: éª¨æ ¼ãƒ¡ãƒƒã‚·ãƒ¥", use_container_width=True)

            st.divider()
            st.header("2. ã—ã‚ãƒ»ã‚­ãƒ¡è¨ºæ–­ã‚¨ãƒªã‚¢ï¼ˆåºƒç¯„å›²ï¼‰")
            st.write("ã‚ªãƒ¬ãƒ³ã‚¸ï¼ˆã»ã†ã‚Œã„ç·šå‘¨è¾ºï¼‰ã¨ãƒ”ãƒ³ã‚¯ï¼ˆå£å…ƒãƒ»ã‚ã”ï¼‰ã®ç¯„å›²ã‚’åºƒã’ã¾ã—ãŸã€‚")
            col1_ana, col2_ana = st.columns(2)
            col1_ana.image(analyzed_a, caption="ç”»åƒA: åˆ†æã‚¨ãƒªã‚¢", use_container_width=True)
            col2_ana.image(analyzed_b, caption="ç”»åƒB: åˆ†æã‚¨ãƒªã‚¢", use_container_width=True)

            st.divider()
            st.header("3. è‚ŒçŠ¶æ…‹ã®æ•°å€¤åŒ–")
            
            metric_cols = st.columns(3)
            targets = ["ãŠã§ã“", "ã»ã†ã‚Œã„ç·šå‘¨è¾º", "å£å…ƒãƒ»ã‚ã”å‘¨ã‚Š"]
            
            for i, target in enumerate(targets):
                with metric_cols[i]:
                    st.subheader(f"â–  {target}")
                    score_a = scores_a[target]
                    score_b = scores_b[target]
                    delta = score_b - score_a
                    
                    st.metric("ç”»åƒA", f"{score_a:.1f}")
                    st.metric("ç”»åƒB", f"{score_b:.1f}", delta=f"{delta:.1f}", delta_color="inverse")
            
            st.info("ğŸ’¡ ç¯„å›²ã‚’åºƒã’ãŸãŸã‚ã€ä»¥å‰ã‚ˆã‚Šæ•°å€¤ãŒå¤§ãããªã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ãŒã€æ¯”è¼ƒï¼ˆå·®åˆ†ï¼‰ã«ã¯å•é¡Œã‚ã‚Šã¾ã›ã‚“ã€‚")

        else:
            st.error("ã©ã¡ã‚‰ã‹ã®ç”»åƒã‹ã‚‰é¡”ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
elif file_a or file_b:
    st.info("æ¯”è¼ƒã®ãŸã‚ã«ã€ã‚‚ã†1æšã®ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
